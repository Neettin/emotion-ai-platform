{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "r_Cq4UkCR1qO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required NLTK data\n",
    "nltk.download('stopwords', quiet=True)\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing functions\n",
    "def remove_punc(txt):\n",
    "    return txt.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def remove_numbers(txt):\n",
    "    return ''.join([i for i in txt if not i.isdigit()])\n",
    "\n",
    "def remove_stopwords(txt):\n",
    "    words = txt.split()\n",
    "    cleaned = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(cleaned)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Complete preprocessing pipeline\"\"\"\n",
    "    text = text.lower()\n",
    "    text = remove_punc(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv('train.txt', sep=';', header=None, names=['text', 'emotions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go feeling hopeless damned hopeful around some...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing minute post feel greedy wrong</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ever feeling nostalgic fireplace know still pr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feeling grouchy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotions\n",
       "0                              didnt feel humiliated         0\n",
       "1  go feeling hopeless damned hopeful around some...         0\n",
       "2          im grabbing minute post feel greedy wrong         1\n",
       "3  ever feeling nostalgic fireplace know still pr...         2\n",
       "4                                    feeling grouchy         1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 16000 samples\n",
      "Emotions: ['sadness' 'anger' 'love' 'surprise' 'fear' 'joy']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset size: {len(df)} samples\")\n",
    "print(f\"Emotions: {df['emotions'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create emotion to number mapping\n",
    "unique_emotions = df['emotions'].unique()\n",
    "emotions_numbers = {em: i for i, em in enumerate(unique_emotions)}\n",
    "number_to_emotions = {i: em for em, i in emotions_numbers.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save emotion mappings\n",
    "with open('emotion_mappings.pkl', 'wb') as f:\n",
    "    pickle.dump({'emotions_to_numbers': emotions_numbers, \n",
    "                 'numbers_to_emotions': number_to_emotions}, f)\n",
    "\n",
    "df['emotions'] = df['emotions'].map(emotions_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text...\n"
     ]
    }
   ],
   "source": [
    "# Preprocess text\n",
    "print(\"Preprocessing text...\")\n",
    "df['text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['emotions'], \n",
    "    test_size=0.20, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TF-IDF vectorizer...\n"
     ]
    }
   ],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "print(\"Creating TF-IDF vectorizer...\")\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training optimized Logistic Regression model...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "Best Parameters: {'C': 10, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "Best CV Accuracy: 0.8818\n"
     ]
    }
   ],
   "source": [
    "# Train best model with GridSearchCV\n",
    "print(\"Training optimized Logistic Regression model...\")\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 50],\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "grid_model = GridSearchCV(\n",
    "    LogisticRegression(),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(f\"\\nBest Parameters: {grid_model.best_params_}\")\n",
    "print(f\"Best CV Accuracy: {grid_model.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 0.8869\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "best_model = grid_model.best_estimator_\n",
    "y_pred = best_model.predict(X_test_tfidf)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Set Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness       0.92      0.93      0.93       946\n",
      "       anger       0.90      0.86      0.88       427\n",
      "        love       0.84      0.72      0.78       296\n",
      "    surprise       0.87      0.67      0.76       113\n",
      "        fear       0.87      0.84      0.85       397\n",
      "         joy       0.87      0.94      0.91      1021\n",
      "\n",
      "    accuracy                           0.89      3200\n",
      "   macro avg       0.88      0.83      0.85      3200\n",
      "weighted avg       0.89      0.89      0.89      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[number_to_emotions[i] for i in sorted(number_to_emotions.keys())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model and vectorizer...\n",
      "\n",
      "✓ Model saved as 'best_emotion_model.pkl'\n",
      "✓ Vectorizer saved as 'tfidf_vectorizer.pkl'\n",
      "✓ Emotion mappings saved as 'emotion_mappings.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Save the best model\n",
    "print(\"\\nSaving model and vectorizer...\")\n",
    "with open('best_emotion_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "\n",
    "print(\"\\n✓ Model saved as 'best_emotion_model.pkl'\")\n",
    "print(\"✓ Vectorizer saved as 'tfidf_vectorizer.pkl'\")\n",
    "print(\"✓ Emotion mappings saved as 'emotion_mappings.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prediction function\n",
    "def predict_emotion(text):\n",
    "    \"\"\"Predict emotion from text\"\"\"\n",
    "    # Load saved models\n",
    "    with open('best_emotion_model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    with open('tfidf_vectorizer.pkl', 'rb') as f:\n",
    "        vectorizer = pickle.load(f)\n",
    "    with open('emotion_mappings.pkl', 'rb') as f:\n",
    "        mappings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
